{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Example: Prompt+Model+OutputParser\n",
    "\n",
    "- Author: [ChangJun Lee](https://www.linkedin.com/in/cjleeno1/)\n",
    "- Peer Review: [Erika Park](https://www.linkedin.com/in/yeonseo-park-094193198/), [Wooseok Jeong](https://github.com/jeong-wooseok)\n",
    "- Proofread : [Q0211](https://github.com/Q0211)\n",
    "- This is a part of [LangChain Open Tutorial](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial)\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/06-LangChain-Expression-Language(LCEL).ipynb)\n",
    "[![Open in GitHub](https://img.shields.io/badge/Open%20in%20GitHub-181717?style=flat-square&logo=github&logoColor=white)](https://github.com/LangChain-OpenTutorial/LangChain-OpenTutorial/blob/main/01-Basic/06-LangChain-Expression-Language(LCEL).ipynb)\n",
    "\n",
    "\n",
    "## Overview\n",
    "\n",
    "The most fundamental and commonly used case involves linking a prompt template with a model. To illustrate how this works, let us create a chain that asks for the capital cities of various countries.\n",
    "\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [Overview](#overview)\n",
    "- [Environment Setup](#environment-setup)\n",
    "- [Utilizing Prompt Templates](#utilizing-prompt-templates)\n",
    "- [Chain Creation](#chain-creation)\n",
    "\n",
    "### References\n",
    "\n",
    "- [LangChain ChatOpenAI API reference](https://python.langchain.com/api_reference/openai/chat_models/langchain_openai.chat_models.base.ChatOpenAI.html)\n",
    "- [LangChain Core Output Parsers](https://python.langchain.com/api_reference/core/output_parsers/langchain_core.output_parsers.list.CommaSeparatedListOutputParser.html#)\n",
    "- [Python List Tutorial](https://docs.python.org/3.13/tutorial/datastructures.html)\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "Set up the environment. You may refer to [Environment Setup](https://wikidocs.net/257836) for more details.\n",
    "\n",
    "**[Note]**\n",
    "- ```langchain-opentutorial``` is a package that provides a set of easy-to-use environment setup, useful functions and utilities for tutorials. \n",
    "- You can checkout the [```langchain-opentutorial```](https://github.com/LangChain-OpenTutorial/langchain-opentutorial-pypi) for more details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install langchain-opentutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "from langchain_opentutorial import package\n",
    "\n",
    "package.install(\n",
    "    [\n",
    "        \"langsmith\",\n",
    "        \"langchain\",\n",
    "        \"langchain_openai\",\n",
    "        \"langchain_community\",\n",
    "    ],\n",
    "    verbose=False,\n",
    "    upgrade=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables have been set successfully.\n"
     ]
    }
   ],
   "source": [
    "# Set environment variables\n",
    "from langchain_opentutorial import set_env\n",
    "\n",
    "set_env(\n",
    "    {\n",
    "        \"OPENAI_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_API_KEY\": \"\",\n",
    "        \"LANGCHAIN_TRACING_V2\": \"true\",\n",
    "        \"LANGCHAIN_ENDPOINT\": \"https://api.smith.langchain.com\",\n",
    "        \"LANGCHAIN_PROJECT\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "You can alternatively set ```OPENAI_API_KEY``` in ```.env``` file and load it. \n",
    "\n",
    "[Note] This is not necessary if you've already set ```OPENAI_API_KEY``` in previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configuration File for Managing API Key as an Environment Variable\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API KEY Information\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up LangSmith tracking: https://smith.langchain.com\n",
    "from langsmith import utils\n",
    "\n",
    "utils.tracing_is_enabled()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizing Prompt Templates\n",
    "\n",
    "```PromptTemplate```\n",
    "\n",
    "- A prompt template is used to create a complete prompt string by incorporating the user's input variables.\n",
    "- Usage\n",
    "  - ```template```: A template string is a predefined format where curly braces '{}' are used to represent variables.\n",
    "\n",
    "  - ```input_variables```: The names of the variables to be inserted within the curly braces are defined as a list.\n",
    "\n",
    "```input_variables```\n",
    "\n",
    "- ```input_variables``` is a list that defines the names of the variables used in the ```PromptTemplate```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```from_template()``` method is used to create a ```PromptTemplate``` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['country'], input_types={}, partial_variables={}, template='What is the capital of {country}?')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define template\n",
    "template = \"What is the capital of {country}?\"\n",
    "\n",
    "# Create a `PromptTemplate` object using the `from_template` method.\n",
    "prompt_template = PromptTemplate.from_template(template)\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of Korea?'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"Korea\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is the capital of USA?'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate the prompt.\n",
    "prompt = prompt_template.format(country=\"USA\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Creation\n",
    "\n",
    "### LCEL (LangChain Expression Language)\n",
    "\n",
    "Here, we use LCEL to combine various components into a single chain.\n",
    "\n",
    "![lcel.png](./assets/02-langchain-expression-language.png)\n",
    "\n",
    "```\n",
    "chain = prompt | model | output_parser\n",
    "```\n",
    "\n",
    "The ```|``` symbol works similarly to the [Unix pipe operator](<https://en.wikipedia.org/wiki/Pipeline_(Unix)>), linking different components and passing the output of one component as the input to the next.\n",
    "\n",
    "In this chain, user input is passed to the prompt template, and the output from the prompt template is then forwarded to the model. By examining each component individually, you can understand what happens at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the prompt as a `PromptTemplate` object.\n",
    "prompt = PromptTemplate.from_template(\"Please explain {topic} in simple terms.\")\n",
    "\n",
    "\n",
    "# Combine the prompt and model into a chain\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling ```invoke()```\n",
    "\n",
    "- Input values are provided in the form of a Python dictionary (key-value pairs).  \n",
    "- When calling the ```invoke()``` function, these input values are passed as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the topic in the `input` dictionary to 'The Principles of Learning in Artificial Intelligence Models'.\n",
    "input = {\"topic\": \"The Principles of Learning in Artificial Intelligence Models\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Sure! The principles of learning in artificial intelligence (AI) models can be understood through a few key concepts. Here’s a simple breakdown:\\n\\n1. **Data**: AI models learn from data. Just like humans learn from experiences, AI systems learn from examples. The more quality data they have, the better they can learn.\\n\\n2. **Patterns**: AI looks for patterns in the data. For instance, if you show an AI many pictures of cats and dogs, it will try to find features that distinguish the two, like fur patterns or ear shapes.\\n\\n3. **Training**: This is the process where the AI model learns from the data. During training, the model adjusts its internal settings (called parameters) to improve its predictions or decisions based on the examples it sees.\\n\\n4. **Feedback**: After making predictions, the AI receives feedback on how well it did. This feedback helps the model adjust and improve. For example, if it incorrectly identifies a cat as a dog, it learns from that mistake.\\n\\n5. **Generalization**: The goal of an AI model is to generalize from the training data to new, unseen data. This means it should be able to make accurate predictions even when it encounters situations it hasn't seen before.\\n\\n6. **Overfitting and Underfitting**: \\n   - **Overfitting** happens when a model learns the training data too well, including noise and outliers, making it perform poorly on new data.\\n   - **Underfitting** occurs when a model is too simple to capture the underlying patterns in the data, leading to poor performance on both training and new data.\\n\\n7. **Iteration**: Learning is often an iterative process. AI models are trained, tested, and refined multiple times to improve their accuracy and performance.\\n\\n8. **Algorithms**: Different algorithms (methods) are used for learning. Some common ones include decision trees, neural networks, and support vector machines. Each has its strengths and weaknesses depending on the task.\\n\\n9. **Evaluation**: After training, the model is evaluated using separate data to see how well it performs. This helps ensure that it can generalize well to new situations.\\n\\nIn summary, AI models learn by analyzing data, finding patterns, receiving feedback, and adjusting their approach to make better predictions. The process involves careful balancing to ensure they learn effectively without becoming too specialized or too simplistic.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 484, 'prompt_tokens': 21, 'total_tokens': 505, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_560af6e559', 'finish_reason': 'stop', 'logprobs': None}, id='run-827505fa-b70c-4419-8ab8-0ec27fe854b8-0', usage_metadata={'input_tokens': 21, 'output_tokens': 484, 'total_tokens': 505, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Connect the `prompt` object and the `model` object using the pipe (`|`) operator.\n",
    "# Use the `invoke` method to pass the `input`.\n",
    "# This will return the message generated by the AI model.\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of outputting a streaming response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the basic ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more high-quality data they have, the better they can learn. Think of it like a student studying for a test; the more information they have, the better they can prepare.\n",
      "\n",
      "2. **Learning from Examples**: AI models often learn by looking at examples. For instance, if you want to teach an AI to recognize cats in pictures, you show it many pictures of cats and non-cats. The model learns to identify patterns that distinguish cats from other objects.\n",
      "\n",
      "3. **Feedback Loop**: AI models improve through feedback. After making predictions, they receive feedback on whether they were right or wrong. This feedback helps them adjust and make better predictions in the future, similar to how a coach helps an athlete improve by pointing out mistakes.\n",
      "\n",
      "4. **Generalization**: A good AI model can generalize from the examples it has seen to make predictions about new, unseen data. This means it can apply what it learned to situations it hasn't encountered before, much like how a person can apply knowledge from one subject to another.\n",
      "\n",
      "5. **Overfitting and Underfitting**: These are common problems in AI learning. Overfitting happens when a model learns the training data too well, including noise and outliers, making it perform poorly on new data. Underfitting occurs when a model is too simple to capture the underlying patterns in the data. The goal is to find a balance where the model learns enough to perform well without memorizing the training data.\n",
      "\n",
      "6. **Continuous Learning**: AI models can continue to learn and improve over time. This is similar to how people keep learning new things throughout their lives. Some models can adapt to new data as it comes in, which helps them stay relevant and accurate.\n",
      "\n",
      "7. **Algorithms Matter**: The methods or algorithms used to train AI models are crucial. Different algorithms can lead to different results, just like different study techniques can lead to different levels of understanding for a student.\n",
      "\n",
      "8. **Evaluation and Testing**: To know how well an AI model is performing, it needs to be evaluated using separate data that it hasn't seen before. This helps ensure that the model is not just memorizing but truly learning.\n",
      "\n",
      "In summary, the principles of learning in AI models revolve around using data effectively, learning from examples, receiving feedback, generalizing knowledge, avoiding common pitfalls, and continuously improving. These principles help create AI systems that can perform tasks intelligently and adapt to new challenges."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token.content, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Parser\n",
    "\n",
    "An **Output Parser** is a tool designed to transform or process the responses from an AI model into a specific format. Since the model's output is typically provided as free-form text, an **Output Parser** is essential to convert it into a structured format or extract the required data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "output_parser = (\n",
    "    StrOutputParser()\n",
    ")  # Directly returns the model's response as a string without modification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An output parser is added to the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A processing chain is constructed by connecting the prompt, model, and output parser.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sure! The Principles of Learning in Artificial Intelligence (AI) Models can be understood as the fundamental ideas that guide how AI systems learn from data and improve their performance over time. Here are some key principles explained in simple terms:\\n\\n1. **Data-Driven Learning**: AI models learn from data. The more relevant and high-quality data they have, the better they can learn patterns and make predictions. Think of it like a student learning from textbooks; the more information they have, the more they can understand.\\n\\n2. **Generalization**: This is the ability of an AI model to apply what it has learned from training data to new, unseen data. For example, if a model learns to recognize cats from pictures of cats, it should also be able to recognize a cat it has never seen before.\\n\\n3. **Feedback and Adjustment**: AI models often use feedback to improve. After making predictions, they can compare their results to the correct answers and adjust their internal parameters to reduce errors. This is similar to how a student learns from mistakes on a test.\\n\\n4. **Iteration**: Learning is usually an iterative process. AI models go through multiple cycles of training, testing, and refining. Each cycle helps the model improve its accuracy and performance, much like practicing a skill repeatedly to get better at it.\\n\\n5. **Feature Extraction**: AI models need to identify important characteristics (features) in the data that help them make decisions. For example, in image recognition, features might include edges, colors, or shapes. This is like a person focusing on key details when trying to recognize something.\\n\\n6. **Overfitting and Underfitting**: These are common challenges in AI learning. Overfitting happens when a model learns the training data too well, including noise and outliers, making it perform poorly on new data. Underfitting occurs when a model is too simple to capture the underlying patterns in the data. Balancing these is crucial for effective learning.\\n\\n7. **Transfer Learning**: This principle involves taking knowledge gained from one task and applying it to a different but related task. For example, a model trained to recognize dogs might be adapted to recognize other animals with less additional training.\\n\\n8. **Reinforcement Learning**: In this approach, an AI learns by interacting with an environment and receiving rewards or penalties based on its actions. It’s like training a pet; you reward good behavior and discourage bad behavior to shape their actions.\\n\\n9. **Scalability**: AI models should be able to handle increasing amounts of data and complexity without a significant drop in performance. This is important as the amount of data available continues to grow.\\n\\n10. **Ethics and Fairness**: As AI systems learn from data, it’s essential to ensure they do so in a way that is fair and ethical. This means being aware of biases in the data and striving to create models that treat all individuals and groups fairly.\\n\\nThese principles help guide the development and training of AI models, ensuring they learn effectively and can be applied to real-world problems.'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the invoke method of the chain object to pass the input\n",
    "chain.invoke(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure! The principles of learning in artificial intelligence (AI) models can be understood as the basic ideas that guide how these models learn from data. Here are some key principles explained in simple terms:\n",
      "\n",
      "1. **Data is Key**: AI models learn from data. The more relevant and high-quality data you provide, the better the model can learn. Think of it like teaching a child; the more books and experiences they have, the more they learn.\n",
      "\n",
      "2. **Patterns and Features**: AI looks for patterns in the data. It identifies important features (characteristics) that help it make decisions or predictions. For example, if you’re teaching an AI to recognize cats, it will learn features like fur, whiskers, and ears.\n",
      "\n",
      "3. **Learning from Examples**: AI models learn by example. They are trained on a set of data (called the training set) where they see inputs and the correct outputs. Over time, they adjust their internal rules to improve their predictions.\n",
      "\n",
      "4. **Feedback Loop**: After making predictions, AI models receive feedback on how well they did. This feedback helps them adjust and improve. It’s like getting grades on homework; you learn what you did right and what you need to work on.\n",
      "\n",
      "5. **Generalization**: A good AI model can generalize, meaning it can apply what it learned from the training data to new, unseen data. This is important because you want the model to perform well in real-world situations, not just on the examples it was trained on.\n",
      "\n",
      "6. **Overfitting and Underfitting**: These are two common problems in learning. Overfitting happens when a model learns too much from the training data, including noise and outliers, making it perform poorly on new data. Underfitting occurs when a model doesn’t learn enough, missing important patterns. The goal is to find a balance.\n",
      "\n",
      "7. **Iterative Improvement**: Learning is often an iterative process. Models are trained, tested, and refined multiple times to improve their performance. This is similar to practicing a skill repeatedly until you get better at it.\n",
      "\n",
      "8. **Different Learning Types**: There are various ways AI can learn, such as:\n",
      "   - **Supervised Learning**: Learning from labeled data (input-output pairs).\n",
      "   - **Unsupervised Learning**: Finding patterns in data without labels.\n",
      "   - **Reinforcement Learning**: Learning by trial and error, receiving rewards or penalties based on actions taken.\n",
      "\n",
      "9. **Scalability**: AI models can often learn from large amounts of data, which allows them to improve as more data becomes available. This is like a student who keeps reading more books and gaining more knowledge.\n",
      "\n",
      "10. **Transfer Learning**: Sometimes, models can take knowledge learned from one task and apply it to another related task. This is like a person who learns to play the piano and then finds it easier to learn the keyboard.\n",
      "\n",
      "In summary, the principles of learning in AI models revolve around using data to find patterns, receiving feedback, and continuously improving to make accurate predictions or decisions."
     ]
    }
   ],
   "source": [
    "# Request for Streaming Output\n",
    "answer = chain.stream(input)\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying and Modifying Templates\n",
    "\n",
    "- The prompt content below can be **modified** as needed for testing purposes.  \n",
    "- The ```model_name``` can also be adjusted for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "You are a seasoned English teacher with 10 years of experience. Please write an English conversation suitable for the given situation.  \n",
    "Refer to the [FORMAT] for the structure.\n",
    "\n",
    "#SITUATION:\n",
    "{question}\n",
    "\n",
    "#FORMAT:\n",
    "- Dialogue in English:\n",
    "- Explanation of the Dialogue: \n",
    "\"\"\"\n",
    "\n",
    "# Generate the prompt using the PromptTemplate\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "# Initialize the ChatOpenAI model.\n",
    "model = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
    "\n",
    "# Initialize the string output parser.\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the chain.\n",
    "chain = prompt | model | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Dialogue in English:\n",
      "**Student**: Hi, could you help me understand the differences between \"restroom,\" \"toilet,\" and \"bathroom\"? I always get confused.\n",
      "\n",
      "**Teacher**: Of course! In American English, \"restroom\" is often used in public places, like restaurants or schools. It’s a polite way to refer to the facilities.\n",
      "\n",
      "**Student**: Okay, so when would I use \"toilet\"?\n",
      "\n",
      "**Teacher**: \"Toilet\" usually refers to the actual fixture or the room that contains the toilet. It's more commonly used in British English. \n",
      "\n",
      "**Student**: Got it! And what about \"bathroom\"?\n",
      "\n",
      "**Teacher**: \"Bathroom\" generally refers to a room that has a toilet and a sink, and often a bathtub or shower as well. It’s usually used in homes.\n",
      "\n",
      "**Student**: So, to summarize: \"restroom\" is for public places, \"toilet\" is the fixture, and \"bathroom\" is usually in a house?\n",
      "\n",
      "**Teacher**: Exactly! You’ve got it!\n",
      "\n",
      "---\n",
      "\n",
      "- Explanation of the Dialogue:\n",
      "In this conversation, a student seeks clarification on the terms \"restroom,\" \"toilet,\" and \"bathroom.\" The teacher explains that \"restroom\" is a polite term used in public settings, \"toilet\" refers to the actual toilet fixture and is more common in British English, while \"bathroom\" denotes a room typically found in homes that includes a toilet and other facilities. This dialogue helps the student understand the context and usage of these terms effectively.\n"
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response.\n",
    "print(chain.invoke({\"question\": \"I want to go to a restaurant and order food.\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- **Dialogue in English:**\n",
      "\n",
      "**Customer:** Hi there! Can I see the menu, please?\n",
      "\n",
      "**Waiter:** Of course! Here you go. Would you like anything to drink while you look?\n",
      "\n",
      "**Customer:** Yes, I’d like a glass of water, please.\n",
      "\n",
      "**Waiter:** Sure! I’ll get that for you right away. Have you decided on your meal?\n",
      "\n",
      "**Customer:** Yes, I think I’ll have the grilled chicken salad.\n",
      "\n",
      "**Waiter:** Great choice! Would you like any dressing on that?\n",
      "\n",
      "**Customer:** Yes, can I have the vinaigrette, please?\n",
      "\n",
      "**Waiter:** Absolutely! Is there anything else you’d like to add to your order?\n",
      "\n",
      "**Customer:** No, that will be all for now. Thank you!\n",
      "\n",
      "**Waiter:** You’re welcome! I’ll be back shortly with your water and salad.\n",
      "\n",
      "---\n",
      "\n",
      "- **Explanation of the Dialogue:**\n",
      "\n",
      "In this conversation, the customer initiates the interaction by asking to see the menu, indicating they are ready to order. The waiter responds politely and offers a drink, showing good customer service. The customer orders a glass of water and then chooses a meal, which is the grilled chicken salad. The waiter asks for any preferences regarding dressing, demonstrating attentiveness to the customer's needs. The customer specifies a dressing and concludes the order, while the waiter confirms and assures the customer that their order will be taken care of. This exchange reflects a typical restaurant ordering process, highlighting polite conversation and clear communication between the customer and the waiter."
     ]
    }
   ],
   "source": [
    "# Execute the completed Chain to obtain a response\n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"I want to go to a restaurant and order food.\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Dialogue in English:**\n",
      "\n",
      "**Customer:** (nervously) Hi there! I’d like to order a quantum uranium pizza, please. \n",
      "\n",
      "**Waiter:** (raising an eyebrow) A what? I’ve never heard of that before. \n",
      "\n",
      "**Customer:** (glancing around) You know, the one with all the exotic toppings and a supercharged crust? \n",
      "\n",
      "**Waiter:** (confused) Uh, we just have regular pizzas here. Are you sure you don’t mean a supreme or something? \n",
      "\n",
      "**Customer:** (whispering) No, no! It’s very important I get that pizza. I’m in a bit of a hurry.\n",
      "\n",
      "**Waiter:** (leaning closer) Why the rush? \n",
      "\n",
      "**Customer:** (suddenly looking terrified) Because the FBI is outside! \n",
      "\n",
      "**Waiter:** (wide-eyed) The FBI? What did you do? \n",
      "\n",
      "**Customer:** (frantically) I didn’t do anything! It’s all a misunderstanding! Just please, can you make that pizza quickly? \n",
      "\n",
      "**Waiter:** (nervously) Alright, alright! One quantum uranium pizza coming right up! \n",
      "\n",
      "**Customer:** (sighing in relief) Thank you! I’ll pay extra for it to go.\n",
      "\n",
      "**Waiter:** (rushing to the kitchen) Just stay calm! I’ll hurry!\n",
      "\n",
      "**Customer:** (looking out the window) They’re getting closer! I need that pizza fast!\n",
      "\n",
      "---\n",
      "\n",
      "**Explanation of the Dialogue:**\n",
      "\n",
      "In this conversation, the customer is at a pub trying to order a very unusual pizza called a \"quantum uranium pizza.\" The waiter is initially confused by the strange request, showcasing a typical misunderstanding for comedic effect. The customer’s anxiety escalates when they reveal they are being chased by the FBI, which adds a sense of urgency and tension to the scene. The exchange highlights the contrast between the mundane setting of a pub and the bizarre situation of being pursued by federal agents. The customer’s frantic demeanor and the waiter’s surprised reactions create a humorous yet tense atmosphere, emphasizing the absurdity of the situation. This dialogue illustrates the use of humor in high-stress scenarios, making it engaging and entertaining."
     ]
    }
   ],
   "source": [
    "# This time, set the question to 'Ordering Pizza in the US' and execute it.\n",
    "# Request for Streaming Output\n",
    "answer = chain.stream({\"question\": \"Ordering a quantum uranium pizza at a pub and being chased by the FBI\"})\n",
    "\n",
    "# Streaming Output\n",
    "for token in answer:\n",
    "    print(token, end=\"\", flush=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-opentutorial-xFIp9mn7-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
